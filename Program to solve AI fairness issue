import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from fairlearn.reductions import ExponentiatedGradient, DemographicParity
from fairlearn.metrics import MetricFrame, selection_rate

# Step 1: Create a synthetic dataset with bias
X, y = make_classification(n_samples=1000, n_features=5, random_state=42)
sensitive_feature = np.random.choice([0, 1], size=(1000,), p=[0.7, 0.3])  # Bias: more males (0)

# Step 2: Split the dataset into training and test sets
X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(
    X, y, sensitive_feature, test_size=0.2, random_state=42
)

# Step 3: Train a model on the original dataset
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Step 4: Evaluate the model on the test set
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the original model: {accuracy:.4f}")

# Step 5: Calculate fairness metrics (Selection rate for sensitive groups)
metric_frame = MetricFrame(
    metrics={"selection_rate": selection_rate},
    y_true=y_test,
    y_pred=y_pred,
    sensitive_features=sensitive_test
)
print("Fairness metrics (Selection rate):")
print("Overall selection rate:", metric_frame.overall)  # Overall selection rate
print("Selection rate by group:")
print(metric_frame.by_group)  # Selection rate by group (gender in this case)

# Step 6: Apply fairness mitigation using ExponentiatedGradient (DemographicParity)
fair_clf = ExponentiatedGradient(
    estimator=RandomForestClassifier(random_state=42),
    constraints=DemographicParity()
)
fair_clf.fit(X_train, y_train, sensitive_features=sensitive_train)

# Step 7: Retrain the model with fairness mitigation
y_pred_fair = fair_clf.predict(X_test)
accuracy_fair = accuracy_score(y_test, y_pred_fair)
print(f"Accuracy of the fair model: {accuracy_fair:.4f}")

# Recalculate fairness metrics for the fair model
metric_frame_fair = MetricFrame(
    metrics={"selection_rate": selection_rate},
    y_true=y_test,
    y_pred=y_pred_fair,
    sensitive_features=sensitive_test
)
print("Fairness metrics (Selection rate) after fairness mitigation:")
print("Overall selection rate after fairness mitigation:", metric_frame_fair.overall)  # Overall selection rate
print("Selection rate by group after fairness mitigation:")
print(metric_frame_fair.by_group)  # Selection rate by group (gender in this case)
